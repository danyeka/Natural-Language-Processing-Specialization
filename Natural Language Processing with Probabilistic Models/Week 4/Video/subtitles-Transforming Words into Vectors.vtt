WEBVTT

1
00:00:00.240 --> 00:00:03.741
Given some context words we need
to feed them into a model and

2
00:00:03.741 --> 00:00:05.740
predict the central work.

3
00:00:05.740 --> 00:00:09.635
However, since we might have several
words that are context words,

4
00:00:09.635 --> 00:00:12.340
we have to find a way to represent them.

5
00:00:12.340 --> 00:00:15.240
We also need to find a way to
represent the central world.

6
00:00:15.240 --> 00:00:17.340
So let's take a look at how to do that.

7
00:00:17.340 --> 00:00:21.833
&gt;&gt; So far you've cleaned and tokenize the
corpus and extracted the context words and

8
00:00:21.833 --> 00:00:26.040
center word from a window that
slides across your prepared corpus.

9
00:00:26.040 --> 00:00:30.186
No, you are ready to transform
the central words and context words into

10
00:00:30.186 --> 00:00:35.340
a mathematical form that can be consumed
by the continuous bag of words model.

11
00:00:35.340 --> 00:00:37.440
Let's start with the central words.

12
00:00:37.440 --> 00:00:41.995
For the sample corpus which is the
sentence I'm happy because I'm learning

13
00:00:41.995 --> 00:00:46.940
you first create a vocabulary which is
the set of unique words in the corpus.

14
00:00:46.940 --> 00:00:54.379
So here you get a five word vocabulary am,
because, happy, I and learning.

15
00:00:54.379 --> 00:00:58.399
You can now encode each word as a column,
one hot vector where each row of

16
00:00:58.399 --> 00:01:01.740
the vector corresponds to
a word of the vocabulary.

17
00:01:01.740 --> 00:01:03.600
So five rows in total here.

18
00:01:03.600 --> 00:01:08.029
By the way, here the words corresponding
to the rows are arranged in

19
00:01:08.029 --> 00:01:11.616
alphabetical order but
any other order would be fine.

20
00:01:11.616 --> 00:01:17.205
In this way the vector for am will have
a one in the row corresponding to am and

21
00:01:17.205 --> 00:01:21.643
zero everywhere else Because
we'll have a one in the row for

22
00:01:21.643 --> 00:01:25.440
because and
zero in the other rows and so on.

23
00:01:25.440 --> 00:01:29.141
This is how you will input
the central words into the model.

24
00:01:29.141 --> 00:01:34.135
For the context words you will create a
single vector that represents the context

25
00:01:34.135 --> 00:01:36.050
from all of the context words.

26
00:01:36.050 --> 00:01:37.677
To create this vector for

27
00:01:37.677 --> 00:01:43.040
the entire context take the average of
one hot vectors of each context word.

28
00:01:43.040 --> 00:01:47.542
For example, if the context words are I,

29
00:01:47.542 --> 00:01:52.173
am, because, I they won't have extra for

30
00:01:52.173 --> 00:01:58.606
the individual words are 00010 for
I, 10000 for

31
00:01:58.606 --> 00:02:04.675
am 0,10004 because and 00010 again for I.

32
00:02:04.675 --> 00:02:09.405
And their average is 1/4,
1/4 0, 1/2 and zero,

33
00:02:09.405 --> 00:02:16.540
which yields the vector representation of
I am because I to be used with a model.

34
00:02:16.540 --> 00:02:17.915
So for the first window,

35
00:02:17.915 --> 00:02:22.371
I'm happy because I the final vector
representations that you will actually use

36
00:02:22.371 --> 00:02:26.340
to train the continuous bag of
words model will look like this.

37
00:02:26.340 --> 00:02:28.190
These are called vectors by the way.

38
00:02:28.190 --> 00:02:32.386
I'm just writing them in a single row to
make everything fits on the slide and so

39
00:02:32.386 --> 00:02:35.340
on for the rest of the training data set.

40
00:02:35.340 --> 00:02:39.680
By now you've concluded the preparation
phase starting from the row corpus.

41
00:02:39.680 --> 00:02:43.940
You now have data that you can use to
train a continuous bag of words model.

42
00:02:43.940 --> 00:02:48.276
Congratulations, up next you'll
examine the details of this model and

43
00:02:48.276 --> 00:02:52.840
get ready to apply your new
skills to this week's assignment.

44
00:02:52.840 --> 00:02:55.959
&gt;&gt; Since you have fully
represented the context words and

45
00:02:55.959 --> 00:03:00.448
central word each as a vector, you are now
ready to learn more about the model.

46
00:03:00.448 --> 00:03:04.661
In the next video we will learn about
the architecture of the CBO model.